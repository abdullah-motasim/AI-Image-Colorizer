# -*- coding: utf-8 -*-
"""ImageColourizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q6wVgC8bOY54x3LGUWFe6dZgCxG9FdC_

# Utility Functions
"""

import numpy as np
from google.colab import drive
import matplotlib.pyplot as plt
import random
import torch
import cv2
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import time
import multiprocessing
import os

# Have to add the APS360_Project folder as shortcut to My Drive in order to read from it
drive.mount('/content/drive', force_remount=True)

def mean_greyscale(img):
    """
    img: numpy array (1.0 RGB) with img.shape = (height, width, channels)
    Assigns the average RGB value for each pixel
    """
    copy = None
    if type(img) == np.ndarray:
        copy = img.copy();
        copy = np.average(copy, axis=2)
    elif type(img) == torch.Tensor:
        copy = img.clone()
        copy = torch.mean(copy, dim=2)
    return copy

def weighted_greyscale(img):
    """
    img: numpy array (1.0 RGB) with img.shape = (height, width, channels)
    Multiplies the RGB values for each pixel by defined constants
    """
    copy = None
    if type(img) == np.ndarray:
        copy = img.copy()
    elif type(img) == torch.Tensor:
        copy = img.clone()
    return copy[:,:,0] * 0.299 + copy[:,:,1] * 0.5870 + copy[:,:,2] * 0.1140

def lightness_greyscale(img):
    """
    img: numpy array (1.0 RGB) with img.shape = (height, width, channels)
    Assigns the max-min for RGB values for each pixel
    """
    copy = None
    if type(img) == np.ndarray:
        copy = img.copy()
        copy = np.max(copy, axis=2) - np.min(copy, axis=2)
    elif type(img) == torch.Tensor:
        copy = img.clone()
        copy =  torch.max(copy, dim=2).values - torch.min(copy, dim=2).values
    return copy

def random_greyscale(img):
    # I made this up
    copy = None
    if type(img) == np.ndarray:
        copy = img.copy();
    elif type(img) == torch.Tensor:
        copy = img.clone()
    r = random.random()
    g = random.random() * (1-r)
    b = 1-r-g
    # print(r, g, b, sum([r,g,b]))
    return copy[:,:,0] * r + copy[:,:,1] * g + copy[:,:,2] * b

greyscale_functions = [mean_greyscale, weighted_greyscale, lightness_greyscale, random_greyscale]

def readImg(path):
    # !ls "/content/drive/MyDrive/APS360_Project"
    img = cv2.imread(path)
    img = cv2.resize(img, (256, 256))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

# https://www.bing.com/images/search?view=detailV2&ccid=mWaTjc93&id=2E4BB4EBE65CCD01BC722D96614345F9A78107EC&thid=OIP.mWaTjc93Y5ya7R2GLp8iVQHaFj&mediaurl=https%3A%2F%2Fi.pinimg.com%2F736x%2F11%2Fc8%2F9d%2F11c89d81aea59cd06ee750ae6b346941--ballons-hot-air-balloons.jpg&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.9966938dcf77639c9aed1d862e9f2255%3Frik%3D7AeBp%252flFQ2GWLQ%26pid%3DImgRaw%26r%3D0&exph=552&expw=736&q=random+colorful+picture+hot+air+balloon&simid=608056069864771090&form=IRPRST&ck=62FCB72BF5D5ECD0F5A9AC114215C408&selectedindex=0&ajaxhist=0&ajaxserp=0&pivotparams=insightsToken%3Dccid_trZU7Qud*cp_CAF1027D86FB9447A77F4086C755F4FE*mid_50C38C3FED449E35E4D7639B10B0C9F1AF0E4BF2*simid_608037747533496033*thid_OIP.trZU7QudtwvPKKC75jPg1gHaFj&vt=0&sim=11&iss=VSI&ajaxhist=0&ajaxserp=0
img = readImg("/content/drive/MyDrive/APS360_Project/TestImage.jpg")/255
print(img.shape)

plt.imshow(img)
plt.show()

grey = mean_greyscale(img)
plt.imshow(grey, cmap='gray')
plt.show()

grey2 = weighted_greyscale(img)
plt.imshow(grey2, cmap='gray')
plt.show()

grey3 = lightness_greyscale(img)
plt.imshow(grey3, cmap='gray')
plt.show()

grey4 = random_greyscale(img)
plt.imshow(grey4, cmap='gray')
plt.show()

import torchvision
# !pip install fiftyone
# import fiftyone as fo
# import fiftyone.zoo as foz

# # https://docs.voxel51.com/tutorials/open_images.html
# train_paths = foz.load_zoo_dataset(
#     "open-images-v7",
#     dataset_dir = "/content/drive/MyDrive/APS360_Project/OpenImages",
#     split="train",
#     label_types=[],
#     max_samples=7000,
#     seed=51,
#     shuffle=True,
# )
# val_paths = foz.load_zoo_dataset(
#     "open-images-v7",
#     dataset_dir = "/content/drive/MyDrive/APS360_Project/OpenImages",
#     split="validation",
#     label_types=[],
#     max_samples=1500,
#     seed=51,
#     shuffle=True,
# )
# test_paths = foz.load_zoo_dataset(
#     "open-images-v7",
#     dataset_dir = "/content/drive/MyDrive/APS360_Project/OpenImages",
#     split="test",
#     max_samples=1500,
#     label_types=[],
#     seed=51,
#     shuffle=True,
# )
# train_paths = [data['filepath'] for data in train_paths]
# val_paths = [data['filepath'] for data in val_paths]
# test_paths = [data['filepath'] for data in test_paths]

def drive_to_runtime():
    if not os.path.exists("/content/OpenImages"):
        !mkdir /content/OpenImages
        !mkdir /content/OpenImages/train
        !cp -r /content/drive/MyDrive/APS360_Project/OpenImages/train/data /content/OpenImages/train
        !mkdir /content/OpenImages/validation
        !cp -r /content/drive/MyDrive/APS360_Project/OpenImages/validation/data /content/OpenImages/validation
        !mkdir /content/OpenImages/test
        !cp -r /content/drive/MyDrive/APS360_Project/OpenImages/test/data /content/OpenImages/test

from os import listdir
def get_paths(path):
    return [path + f for f in listdir(path)]

drive_to_runtime()

train_paths = get_paths("/content/OpenImages/train/data/")
val_paths = get_paths("/content/OpenImages/validation/data/")
test_paths = get_paths("/content/OpenImages/test/data/")

div = 1
train_paths = train_paths[:7000//div]
val_paths = val_paths[:1500//div]
test_paths = test_paths[:1500//div]
print(len(train_paths))
print(len(val_paths))
print(len(test_paths))

class Dataset(torch.utils.data.Dataset):
    def __init__(self, paths):
        self.paths = paths

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, index):
        img = readImg(self.paths[index])
        return (img/255).astype(np.float32)

train_data = Dataset(train_paths)
val_data = Dataset(val_paths)
test_data = Dataset(test_paths)
samples = len(train_data) + len(val_data) + len(test_data)
print(samples)

def get_model_name(name, batch_size, learning_rate, epoch):
    return "{0}_bs{1}_lr{2}_epoch{3}_samples{4}".format(name, batch_size, learning_rate, epoch, samples)

def get_data_loader(data, bs):
    w = multiprocessing.cpu_count()
    return torch.utils.data.DataLoader(data, batch_size=bs, shuffle=True, num_workers=w)

def get_data_loaders(bs):
    return get_data_loader(train_data, bs), get_data_loader(val_data, bs), get_data_loader(test_data, bs)

def to_greyscale(data):
    n = len(data)
    ret = torch.empty(n,1,256,256)
    for i, d in enumerate(data):
        func = random.choice(greyscale_functions)
        ret[i] = func(d).reshape(1,256,256)
    return ret

def plot_training_curve(train_acc, train_loss, val_acc, val_loss):
    n = len(train_acc)

    plt.title("Train vs Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.plot(range(1, n+1), train_acc, label="Train")
    plt.plot(range(1, n+1), val_acc, label="Validation")
    plt.legend(loc="best")
    plt.show()

    plt.title("Train vs Validation Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.plot(range(1, n+1), train_loss, label="Train")
    plt.plot(range(1, n+1), val_loss, label="Validation")
    plt.legend(loc="best")
    plt.show()

def load_save_dict(model, optimizer, path):
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    save_dict = torch.load(path, map_location=device)
    model.load_state_dict(save_dict['model_state_dict'])
    optimizer.load_state_dict(save_dict['optimizer_state_dict'])

def get_last_saved(model, optimizer, batch_size, learning_rate, epochs):
    epoch = 0
    for i in range(epochs):
        if os.path.exists("/content/drive/MyDrive/APS360_Project/Models/" + get_model_name(model.name, batch_size, learning_rate, epoch)): epoch = i
    print("Starting at epoch:", epoch)
    if epoch != 0:
        load_save_dict(model, optimizer, get_model_name(model.name, batch_size, learning_rate, epoch-1))
    return epoch

"""# KNN Baseline Model"""

# from sklearn.neighbors import NearestNeighbors
# from sklearn.metrics import accuracy_score

# def flatten(dataset):
#     return dataset.reshape(len(dataset), -1)

# # Merge train and val since there is no actual model training
# train_data = np.concatenate((train_data, val_data))

# del val_data
# random.seed(123)
# train_grey = train_data.copy()
# for index, img in enumerate(train_grey):
#     func = random.choice(greyscale_functions)
#     train_grey[index] = func(img)

# test_grey = test_data.copy()
# for index, img in enumerate(test_grey):
#     func = random.choice(greyscale_functions)
#     test_grey[index] = func(img)

# Greyscale R G B are equal so remove the 3rd dim
# train_grey = train_grey.reshape(len(train_grey), -1)
# test_grey = test_grey.reshape(len(test_grey), -1)
# print(train_grey.shape)
# print(test_grey.shape)

# knn = NearestNeighbors(n_neighbors=10)
# knn.fit(train_grey)

# distances, indices = knn.kneighbors(test_grey)
# average_color = np.mean(train_data[indices[0]], axis=0)
# out = average_color.reshape(256, 256, 3)

# plt.imshow(test_data[0].reshape(256,256,3))
# plt.show()
# plt.imshow(test_grey[0].reshape(256,256), cmap='gray')
# plt.show()
# plt.imshow(out)
# plt.show()

"""# SVR Baseline Model

"""

# from sklearn.svm import SVR
# from sklearn.multioutput import MultiOutputRegressor

# train_data = train_data.reshape(-1, 3)
# test_data = test_data.reshape(-1, 3)
# train_grey = train_grey.reshape(-1, 1)
# test_grey = test_grey.reshape(-1, 1)

# model = MultiOutputRegressor(SVR(kernel='rbf', max_iter=100))
# for i in range(10):
#     # model.fit(train_grey[:1*256*256], train_data[:1*256*256])
#     model.fit(train_grey[i*256*256:(i+1)*256*256], train_data[i*256*256:(i+1)*256*256])

# test_data = test_data.reshape(-1, 256, 256, 3)
# test_grey = test_grey.reshape(-1, 256, 256)

# from sklearn.metrics import mean_squared_error
# mse = 0
# for k in range(10):
#     img = test_grey[k]
#     pred = model.predict(img.reshape(-1, 1)).reshape(256,256,3)
#     mse += mean_squared_error(test_data[k].reshape(1, -1), pred.reshape(1, -1))
#     # plt.imshow(test_data[k])
#     # plt.show()
#     plt.imshow(pred)
#     plt.show()
# print(mse/10)
# print((mse/10)**0.5)

# from sklearn.svm import SVR
# from sklearn.multioutput import MultiOutputRegressor

# train_data = train_data.reshape(-1, 256*256*3)
# test_data = test_data.reshape(-1, 256*256*3)
# train_grey = train_grey.reshape(-1, 256*256)
# test_grey = test_grey.reshape(-1, 256*256)

# model = MultiOutputRegressor(SVR(kernel='rbf'))
# model.fit(train_grey[:5], train_data[:5])

# test_grey = test_grey.reshape(-1, 256, 256)
# test_data = test_data.reshape(-1, 256, 256, 3)
# for k in range(2):
#     img = test_grey[k].reshape(-1, 256*256)
#     print(img.shape)
#     pred = model.predict(img).reshape(256,256,3)
#     plt.imshow(test_data[k])
#     plt.show()
#     plt.imshow(pred)
#     plt.show()

"""# RGB Model"""

def evaluate(net, loader, criterion):
    total_loss = 0.0
    total_acc = 0.0
    total_epoch = 0
    for i, data in enumerate(loader, 0):
        inputs = to_greyscale(data)
        if torch.cuda.is_available():
            inputs = inputs.cuda()
            data = data.cuda()
        outputs = net(inputs)
        loss = criterion(outputs, data)
        correct = (data == outputs).sum()/256/256/3
        total_acc += correct
        total_loss += loss.item()
        total_epoch += len(data)
    acc = total_acc / total_epoch
    loss = float(total_loss) / (i + 1)
    return acc, loss


def train(model, train_loader, val_loader, batch_size=None, learning_rate=0.001, epochs=10, save_model=True, use_saved_model=True, skip_eval_old=False):
    torch.manual_seed(123)
    random.seed(123)

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    train_acc = np.zeros(epochs)
    train_loss = np.zeros(epochs)
    val_acc = np.zeros(epochs)
    val_loss = np.zeros(epochs)

    start_time = time.time()

    start_epoch = 0
    if use_saved_model and skip_eval_old:
        start_epoch = get_last_saved(model, optimizer batch_size, learning_rate, epochs)

    for epoch in range(start_epoch, epochs):
        model_path = "/content/drive/MyDrive/APS360_Project/Models/" + get_model_name(model.name, batch_size, learning_rate, epoch)
        if use_saved_model and os.path.exists(model_path): # Pretrained from another training iteration
            save_dict = torch.load(model_path)
            model.load_state_dict(save_dict['model_state_dict'])
            optimizer.load_state_dict(save_dict['optimizer_state_dict'])
            if skip_eval_old: continue
        else:
            for data in train_loader:
                inputs = to_greyscale(data)
                if torch.cuda.is_available():
                    inputs = inputs.cuda()
                    data = data.cuda()
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, data)
                loss.backward()
                optimizer.step()
        # Calculate the statistics
        train_acc[epoch], train_loss[epoch] = evaluate(model, train_loader, criterion)
        val_acc[epoch], val_loss[epoch] = evaluate(model, val_loader, criterion)
        print(("Epoch {}: Train acc: {}, Train loss: {} | "+ "Validation acc: {}, Validation loss: {}").format(
          epoch + 1, train_acc[epoch], train_loss[epoch], val_acc[epoch], val_loss[epoch]))
        if save_model:
            save_dict = {
              'model_state_dict': model.state_dict(),
              'optimizer_state_dict': optimizer.state_dict()
            }
            torch.save(save_dict, model_path)
    print('Finished Training')
    elapsed_time = time.time() - start_time
    print("Total time elapsed: {:.2f} seconds".format(elapsed_time))
    return train_acc, train_loss, val_acc, val_loss

# def read(names):
#     images = torch.empty(len(names),256,256,3)
#     for i, name in enumerate(names):
#         img = readImg("/content/drive/MyDrive/APS360_Project/OpenImages/train/data/" + name).astype(np.float32)
#         img = torch.from_numpy(img)
#         images[i] = img
#     return images

# train_images = read(["fffcbc0b28c934f7.jpg", "fff4903efe4e622c.jpg", "fff81ac773ffd4b3.jpg", "ffdbd34941344374.jpg", "ffd657a0190d4705.jpg"])
# train_images = get_data_loader(train_images, 1)
# val_images = read(["ffa93c77f0f2255a.jpg", "ff232962a30ba923.jpg", "ff83146c8a3732e5.jpg", "ff70108c0a3e9607.jpg", "ff114c1f0ec8651a.jpg"])
# val_images = get_data_loader(val_images, 1)
# model = Model2()
# values = train(model, train_images, val_images, epochs=100, save_model=False)
# plot_training_curve(*values)

"""# Model 1
* Can't even run this model it takes too much RAM
"""

class Model(nn.Module):
    def __init__(self):
      super(Model, self).__init__()
      self.name = "Model1"
      self.pool = nn.MaxPool2d(2,2)
      # Convolutions
      k = [3,7,11,23,53,129]
      self.conv1 = nn.Conv2d(1, k[0], 3)
      self.conv2 = nn.Conv2d(k[0], k[1], 3)
      self.conv3 = nn.Conv2d(k[1], k[2], 3)
      self.conv4 = nn.Conv2d(k[2], k[3], 3)
      self.conv5 = nn.Conv2d(k[3], k[4], 3)
      self.conv6 = nn.Conv2d(k[4], k[5], 3)
      # Fully Connected Layers
      size = (256-2)//2  # conv1 + pool
      size = (size-2) # conv2
      size = (size-2)//2 # conv3 + pool
      size = (size-2)//2 # conv4 + pool
      size = (size-2) # conv5
      size = (size-2)//2 # conv6 + pool

      self.fc_size = size * size * k[5]
      self.fc1 = nn.Linear(self.fc_size, 3923)
      self.fc2 = nn.Linear(3923, 1475)
      self.fc3 = nn.Linear(1475, 256*256*3)


    def forward(self, x):
      # Convolutions
      x = self.pool(F.relu(self.conv1(x)))
      x = F.relu(self.conv2(x))
      x = self.pool(F.relu(self.conv3(x)))
      x = self.pool(F.relu(self.conv4(x)))
      x = F.relu(self.conv5(x))
      x = self.pool(F.relu(self.conv6(x)))
      # Fully Connected
      x = x.view(-1, self.fc_size)
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)
      x = F.sigmoid(x).view(-1,256,256,3)
      return x

# train_loader, val_loader, test_loader = get_data_loaders(64)
train_loader, val_loader = get_data_loader(train_data, 1), get_data_loader(train_data, 1)
model = Model()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, epochs=250, batch_size=1, save_model=False, use_saved_model=False, skip_eval_old=True)

"""# Model 2


*   Can't overfit 1 image for 500 epochs when using all 4 greyscale functions
* Kinda overfits for 1 image on mean_greyscale function only -> loss: 0.004632371477782726


"""

class Model2(nn.Module):
    def __init__(self):
        super(Model2, self).__init__()
        self.name = "CNNAutoEncoder"
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded.permute(0,2,3,1)

# train_loader, val_loader, test_loader = get_data_loaders(64)
train_loader, val_loader = get_data_loader(train_data, 1), get_data_loader(train_data, 1)
model = Model2()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, epochs=500, batch_size=64, save_model=False, use_saved_model=False, skip_eval_old=False)

"""# Model 3
* Doesn't overfit 500 epochs to 1 image with only mean_greyscale
"""

class Model3(nn.Module):
    def __init__(self):
        super(Model3, self).__init__()
        self.name = "CNNAutoEncoderV2"
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded.permute(0,2,3,1)

# train_loader, val_loader, test_loader = get_data_loaders(64)
train_loader, val_loader = get_data_loader(train_data, 1), get_data_loader(train_data, 1)
model = Model3()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, epochs=500, save_model=False, use_saved_model=False, skip_eval_old=False)

"""# Unet Model
* Can kinda overfit for 500 epochs for 1 image with only mean_greyscale
"""

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=3):
        super(UNet, self).__init__()
        self.name = "UNet"
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.ConvTranspose2d(128, out_channels, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # Encoder pass
        x1 = self.encoder[0:2](x)
        x2 = self.encoder[2:4](x1)
        x3 = self.encoder[4:6](x2)

        # Decoder pass with skip connections
        y = self.decoder[0:2](x3)
        y = torch.cat([y, x2], dim=1)
        y = self.decoder[2:4](y)
        y = torch.cat([y, x1], dim=1)
        y = self.decoder[4:6](y)

        return y.permute(0,2,3,1)

# train_loader, val_loader, test_loader = get_data_loaders(64)
train_loader, val_loader = get_data_loader(train_data, 1), get_data_loader(train_data, 1)
model = UNet()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, epochs=500, batch_size=64, save_model=False, use_saved_model=False, skip_eval_old=False)

"""# GAN Model"""

def train_generator(generator, discriminator, grey_images):
    batch_size = len(grey_images)
    fake_images = generator(grey_images)
    outputs = discriminator(grey_images, fake_images)
    # Only looks at fake outputs
    # gets rewarded if we fool the discriminator!
    labels = torch.zeros(batch_size).float()
    if torch.cuda.is_available():
        labels = labels.cuda()
    loss = nn.BCEWithLogitsLoss()(outputs, labels)
    acc = (outputs<0).sum()
    return loss, acc


def train_discriminator(discriminator, generator, real_images, grey_images):
    batch_size = len(grey_images)
    fake_images = generator(grey_images).detach()
    grey_inputs = torch.cat([grey_images, grey_images])
    inputs = torch.cat([real_images, fake_images])
    labels = torch.cat([
        torch.zeros(batch_size), # Real
        torch.ones(batch_size)   # Fake
    ]).float()
    if torch.cuda.is_available():
        labels = labels.cuda()
    outputs = discriminator(grey_inputs, inputs)
    loss = nn.BCEWithLogitsLoss()(outputs, labels)
    acc = ((outputs<0) & (labels==0)).sum() + ((outputs>0) & (labels==1)).sum()
    return loss, acc

def train_gan(generator, discriminator, train_loader, val_loader, lr=0.001, bs=64, epochs=15):
    torch.manual_seed(123)

    gen_optimizer = optim.Adam(generator.parameters(), lr=lr)
    dis_optimizer = optim.Adam(discriminator.parameters(), lr=lr)

    for epoch in range(epochs):
        total_batch = 0
        total_samples = 0
        total_gen_loss = 0.0
        total_dis_loss = 0.0
        total_gen_acc = 0.0
        total_dis_acc = 0.0
        for real in train_loader:
            grey = to_greyscale(real)
            real = real.permute(0,3,1,2)
            if torch.cuda.is_available():
                real = real.cuda()
                grey = grey.cuda()
            # Train Generator
            gen_optimizer.zero_grad()
            gen_loss, gen_acc = train_generator(generator, discriminator, grey)
            gen_loss.backward()
            gen_optimizer.step()
            # Train Discriminator
            dis_optimizer.zero_grad()
            dis_loss, dis_acc = train_discriminator(discriminator, generator, real, grey)
            dis_loss.backward()
            dis_optimizer.step()

            total_batch += 1
            total_samples += 2*len(real)
            total_gen_loss += gen_loss.item()
            total_dis_loss += dis_loss.item()
            total_gen_acc += gen_acc
            total_dis_acc += dis_acc

        total_gen_loss = total_gen_loss/total_batch
        total_dis_loss = total_dis_loss/total_batch
        total_gen_acc = total_gen_acc/total_samples
        total_dis_acc = total_dis_acc/total_samples

        temp = nn.Module(); temp.forward = lambda x:x.permute(0,2,3,1); temp = nn.Sequential(gen, temp)
        val_acc, val_loss = evaluate(temp, val_loader, nn.MSELoss())
        print("Epoch {}: Gen Acc: {} | Gen Loss: {} | Dis Acc: {} | Dis Loss: {}"
          .format(epoch+1, total_gen_acc, total_gen_loss, total_dis_acc, total_dis_loss))
        print("\tVal Acc: {} | Val Loss: {}".format(val_acc, val_loss))

class UNetGenerator(nn.Module):
    def __init__(self, in_channels=1, out_channels=3):
        super(UNetGenerator, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.ConvTranspose2d(128, out_channels, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid()
        )

    def forward(self, grey):
        # batches = len(grey)
        # noise = torch.randn([batches, 1, 256, 256])
        # if torch.cuda.is_available():
        #     noise = noise.cuda()
        # x = torch.cat((noise, grey), 1)
        x = grey
        # Encoder pass
        x1 = self.encoder[0:2](x)
        x2 = self.encoder[2:4](x1)
        x3 = self.encoder[4:6](x2)

        # Decoder pass with skip connections
        y = self.decoder[0:2](x3)
        y = torch.cat([y, x2], dim=1)
        y = self.decoder[2:4](y)
        y = torch.cat([y, x1], dim=1)
        y = self.decoder[4:6](y)

        return y
# Takes noise and greyscale image and generates a new RGB image
# class Generator(nn.Module):
#     def __init__(self):
#         super(Generator, self).__init__()
#         self.name = "Generator"
#         size = (256-7)//2 + 1 # Conv1
#         size = size//2 # Pool
#         size = (size-3)//2 + 1 # Conv2
#         size = size//2 # Pool
#         size = (size-3)//2 + 1 # Conv3
#         self.size = size * size * 128
#         self.conv = nn.Sequential(
#             nn.Conv2d(2, 32, 7, 2),
#             nn.MaxPool2d(2, 2),
#             nn.Conv2d(32, 64, 3, 2),
#             nn.AvgPool2d(2, 2),
#             nn.Conv2d(64, 128, 3, 2)
#         )
#         self.fc = nn.Sequential(
#             nn.Linear(self.size, 5343),
#             nn.LeakyReLU(0.2),
#             nn.Linear(5343, 3232),
#             nn.LeakyReLU(0.2),
#             nn.Linear(3232, 64*64*3),
#             nn.Sigmoid()
#         )
#         self.upscale = lambda x : F.interpolate(x, size=(256, 256), mode='bilinear')
#     def forward(self, grey):
#         batches = len(grey)
#         noise = torch.randn([batches, 1, 256, 256])
#         if torch.cuda.is_available():
#             noise = noise.cuda()
#         x = torch.cat((noise, grey), 1)
#         x = self.conv(x)
#         x = x.view(-1, self.size)
#         x = self.fc(x)
#         x = x.view(batches, 3, 64, 64)
#         x = self.upscale(x)
#         return x


# Takes greyscale image and generated images and guesses if the generated image is original
# class Discriminator(nn.Module):
#     def __init__(self):
#         super(Discriminator, self).__init__()
#         self.name = "Discriminator"
#         size = (256-6)//2 + 1 # Conv1
#         size = size//2 # Pool
#         size = (size-2)//2 + 1 # Conv2
#         size = size//2 # Pool
#         size = (size-2)//2 + 1 # Conv3
#         self.size = size * size * 128
#         self.conv = nn.Sequential(
#             nn.Conv2d(4, 32, 7, 2),
#             nn.MaxPool2d(2, 2),
#             nn.Conv2d(32, 64, 3, 2),
#             nn.MaxPool2d(2, 2),
#             nn.Conv2d(64, 128, 3, 2),
#         )
#         self.fc = nn.Sequential(
#             nn.Linear(self.size, 300),
#             nn.LeakyReLU(0.2),
#             nn.Linear(300, 100),
#             nn.LeakyReLU(0.2),
#             nn.Linear(100, 1)
#         )

#     def forward(self, grey, rgb):
#         x = torch.concat((grey, rgb), 1)
#         x = self.conv(x)
#         x = x.view(-1, self.size)
#         x = self.fc(x)
#         return x.view(-1)

class WeakDiscriminator(nn.Module):
    def __init__(self):
        super(WeakDiscriminator, self).__init__()
        self.name = "WeakDiscriminator"
        size = (256-6)//2 + 1 # Conv1
        size = size//2 # Pool
        size = (size-2)//2 + 1 # Conv2
        size = size//2 # Pool
        self.size = size * size * 4
        print((self.size/4)**0.5)
        self.conv = nn.Sequential(
            nn.Conv2d(4, 4, 7, 2),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(4, 4, 3, 2),
            nn.AvgPool2d(2,2)
        )
        self.fc = nn.Linear(self.size, 1)

    def forward(self, grey, rgb):
        x = torch.concat((grey, rgb), 1)
        x = self.conv(x)
        x = x.view(-1, self.size)
        x = self.fc(x)
        return x.view(-1)

# train_loader, val_loader, test_loader = get_data_loaders(1)
train_loader, val_loader = get_data_loader(train_data, 1), get_data_loader(train_data, 1)
gen = UNetGenerator()
dis = WeakDiscriminator()
if torch.cuda.is_available():
    print("Using Cuda")
    gen.cuda()
    dis.cuda()
train_gan(gen, dis, train_loader, val_loader, bs=64, epochs=1000)
# import gc
# gc.collect()
# with torch.no_grad():
#     torch.cuda.empty_cache()

"""# LAB Colour Scheme

"""

def to_lab(img):
    """
    img is a uint8 numpy array
    """
    img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    return img

def to_rgb(img):
    """
    img is a 1.0 float numpy array
    """
    img = (img*255).round().astype(np.uint8)
    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)
    return img

def cv_greyscale(img):
    img = (img*255).round().astype(np.uint8)
    img = to_lab(img)
    return img[:,:,0]/255

greyscale_functions = [cv_greyscale, mean_greyscale, weighted_greyscale, lightness_greyscale, random_greyscale]
greyscale_functions = [cv_greyscale, mean_greyscale, weighted_greyscale, random_greyscale]


class DatasetLab(torch.utils.data.Dataset):
    def __init__(self, paths):
        self.paths = paths

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, index):
        img = readImg(self.paths[index])
        lab = (to_lab(img)/255).astype(np.float32)
        img = (img/255).astype(np.float32)
        # Random Greyscale Variation
        lab[:,:,0] = random.choice(greyscale_functions)(img)
        return lab


train_data = DatasetLab(train_paths)
val_data = DatasetLab(val_paths)
test_data = DatasetLab(test_paths)
samples = len(train_data) + len(val_data) + len(test_data)
print(samples)

img = train_data[0]
img = to_rgb(img)
plt.imshow(img)
plt.show()

def evaluate(net, loader, criterion):
    total_loss = 0.0
    total_acc = 0.0
    total_epoch = 0
    with torch.no_grad():
        for i, data in enumerate(loader, 0):
            grey = data[:,:,:,0].reshape(-1,1,256,256)
            colour = data[:,:,:,1:3].permute(0,3,1,2)
            if torch.cuda.is_available():
                grey = grey.cuda()
                colour = colour.cuda()
            outputs = net(grey)
            loss = criterion(outputs, colour)
            correct = (colour == outputs).sum()/256/256/2
            total_acc += correct
            total_loss += loss.item()
            total_epoch += len(data)
            del data
    acc = total_acc / total_epoch
    loss = float(total_loss) / (i + 1)
    return acc, loss

def train(model, train_loader, val_loader, batch_size=None, learning_rate=0.001, epochs=10, save_model=True, use_saved_model=True):
    torch.manual_seed(123)
    random.seed(123)

    criterion = nn.L1Loss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    train_acc = np.zeros(epochs)
    train_loss = np.zeros(epochs)
    val_acc = np.zeros(epochs)
    val_loss = np.zeros(epochs)

    start_time = time.time()

    start_epoch = 0
    if use_saved_model:
        start_epoch = get_last_saved(model, optimizer, batch_size, learning_rate, epochs)

    for epoch in range(start_epoch, epochs):
        model_path = "/content/drive/MyDrive/APS360_Project/Models/" + get_model_name(model.name, batch_size, learning_rate, epoch)
        if use_saved_model and os.path.exists(model_path): # Pretrained from another training iteration
            load_save_dict(model, optimizer)
            continue

        for data in train_loader:
            grey = data[:,:,:,0].reshape(-1,1,256,256)
            colour = data[:,:,:,1:3].permute(0,3,1,2)
            if torch.cuda.is_available():
                grey = grey.cuda()
                colour = colour.cuda()
            optimizer.zero_grad()
            outputs = model(grey)
            loss = criterion(outputs, colour)
            loss.backward()
            optimizer.step()
            del data, grey, colour

        if save_model:
            save_dict = {'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}
            torch.save(save_dict, model_path)

        # Calculate the statistics
        train_acc[epoch], train_loss[epoch] = evaluate(model, train_loader, criterion)
        val_acc[epoch], val_loss[epoch] = evaluate(model, val_loader, criterion)
        print(("Epoch {}: Train acc: {}, Train loss: {} | "+ "Validation acc: {}, Validation loss: {}").format(
          epoch + 1, train_acc[epoch], train_loss[epoch], val_acc[epoch], val_loss[epoch]))

    print('Finished Training')
    elapsed_time = time.time() - start_time
    print("Total time elapsed: {:.2f} seconds".format(elapsed_time))
    return train_acc, train_loss, val_acc, val_loss

"""# Lab UNet Model"""

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.2),
            nn.MaxPool2d(2,2)
        )
    def forward(self, x):
        x = self.model(x)
        return x

class ConvTBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvTBlock, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(in_channels*2, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Upsample(scale_factor=2)
        )
    def forward(self, x):
        x = self.model(x)
        return x

class UNetLab(nn.Module):
    def __init__(self, in_channels=1, out_channels=2, variational=False):
        super(UNetLab, self).__init__()
        self.name = "UNetLab"
        self.variational = variational
        # Encoder
        self.encoder = nn.Sequential(
            ConvBlock(in_channels, 8),
            ConvBlock(8, 16),
            ConvBlock(16, 32),
            ConvBlock(32, 64),
            ConvBlock(64, 128),
            ConvBlock(128, 256),
            ConvBlock(256, 512),
            ConvBlock(512, 1024),
        )
        # self.conv_mu = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)
        # self.conv_sigma = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)

        self.decoder = nn.Sequential(
            ConvTBlock(1024, 512),
            ConvTBlock(512, 256),
            ConvTBlock(256, 128),
            ConvTBlock(128, 64),
            ConvTBlock(64, 32),
            ConvTBlock(32, 16),
            ConvTBlock(16, 8),
            ConvTBlock(8, out_channels)
        )
        self.output = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )

    def reparameterize(self, x):
        mu = self.conv_mu(x)
        sigma = self.conv_sigma(x)
        epsilon = torch.randn(*mu.shape)
        if torch.cuda.is_available(): epsilon = epsilon.cuda()
        z = epsilon*sigma + mu
        return z

    def forward(self, x):
        encoder_outputs = []
        for block in self.encoder:
            x = block(x)
            encoder_outputs.append(x)

        # if self.variational: x = self.reparameterize(x)

        for block in self.decoder:
            x = torch.cat([x, encoder_outputs.pop()], dim=1)
            x = block(x)

        return self.output(x)

train_loader, val_loader, test_loader = get_data_loaders(70)
model = UNetLab()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, batch_size=70, learning_rate=0.001, epochs=100, save_model=True, use_saved_model=True)

"""# Lab CNN Model"""

class LabCNN(nn.Module):
    def __init__(self):
        super(LabCNN, self).__init__()

        self.first = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(128),

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(256),

            nn.Upsample(scale_factor=2),
            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(128),

            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2)
        )
        self.second = nn.Sequential(
            nn.Conv2d(65, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.BatchNorm2d(64),

            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        y = self.first(x)
        y = torch.cat([y, x], axis=1)
        y = self.second(y)
        return y

train_loader, val_loader, test_loader = get_data_loaders(70)
model = LabCNN()
if torch.cuda.is_available():
    print("Using Cuda")
    model.cuda()
values = train(model, train_loader, val_loader, learning_rate=0.001, epochs=30, save_model=False, use_saved_model=False, skip_eval_old=False)

"""# Lab GAN"""

import datetime
class GanTrainer():
    def __init__(self, generator, discriminator, lrg=1e-4, lrd=1e-4, epochs=100, bs=70, betas=(0.5, 0.99), L1_rate=100, save_model=True):
        self.lrg = lrg
        self.lrd = lrd
        self.epochs = epochs
        self.bs = bs
        self.betas = betas
        self.L1_rate = L1_rate
        self.time = datetime.datetime.now()
        self.save_model = save_model
        self.start_epoch = 0
        # Init weights
        init_weights(generator)
        init_weights(discriminator)

        if torch.cuda.is_available():
            print("Using Cuda")
            generator.cuda()
            discriminator.cuda()

        self.BCELoss = nn.BCEWithLogitsLoss()
        self.L1Loss = nn.L1Loss()

        self.gen_optimizer = optim.Adam(generator.parameters(), lr=self.lrg, betas=self.betas)
        self.dis_optimizer = optim.Adam(discriminator.parameters(), lr=self.lrd, betas=self.betas)

        self.generator = generator
        self.discriminator = discriminator

        generator.train()
        discriminator.train()

    def start(self):
        self.train_gan(self.generator, self.discriminator)

    def load_gen(self, epoch):
        gen_path = "/content/drive/MyDrive/APS360_Project/Models/Generator_" + get_model_name(self.generator.name, self.bs, self.lrg, epoch)
        load_save_dict(self.generator, self.gen_optimizer, gen_path)

    def load_save(self, epoch):
        self.start_epoch = epoch+1
        gen_path = "/content/drive/MyDrive/APS360_Project/Models/Generator_" + get_model_name(gen.name, self.bs, self.lrg, epoch)
        load_save_dict(self.generator, self.gen_optimizer, gen_path)
        dis_path = "/content/drive/MyDrive/APS360_Project/Models/Discriminator_" + get_model_name(dis.name, self.bs, self.lrd, epoch)
        load_save_dict(self.discriminator, self.dis_optimizer, dis_path)

    def show(self, imgs):
        self.generator.eval()
        plt.figure(figsize=(15, 8))
        for i in range(7):
            # img = sk_greyscale(readImg("/content/drive/MyDrive/APS360_Project/TestImage.jpg")).reshape(1,1,256,256)
            grey = imgs[i,0,:,:].reshape(1,1,256,256)
            generated = torch.cat([grey, self.generator(grey).detach()], dim=1).permute(0,2,3,1).squeeze(0)
            # Plot
            plt.subplot(3, 7, i+1)
            plt.axis("off")
            plt.imshow(grey.cpu().reshape(256,256), cmap='gray')
            plt.subplot(3, 7, i+8)
            plt.axis("off")
            plt.imshow(to_rgb(generated.cpu()))
            plt.subplot(3, 7, i+15)
            plt.axis("off")
            plt.imshow(to_rgb(imgs[i,:,:,:].cpu().permute(1,2,0)))
        plt.show()
        self.generator.train()

    def train_generator(self, generator, discriminator, real_images):
        grey_images = real_images[:,0:1,:,:]
        fake_images = torch.cat([grey_images, generator(grey_images)], dim=1)
        outputs = discriminator(fake_images)
        # Only looks at fake outputs
        labels = torch.ones(outputs.shape).float() # Want our fake images to be real
        if torch.cuda.is_available():
            labels = labels.cuda()
        loss = self.BCELoss(outputs, labels) + self.L1Loss(fake_images[:,1:3,:,:], real_images[:,1:3,:,:]) * self.L1_rate
        return loss

    def train_discriminator(self, discriminator, generator, real_images):
        grey_images = real_images[:,0:1,:,:]
        fake_images = torch.cat([grey_images, generator(grey_images).detach()], dim=1)
        real_outputs = discriminator(real_images)
        fake_outputs = discriminator(fake_images)
        labels_real = torch.ones(real_outputs.shape).float() # Real
        labels_fake = torch.zeros(fake_outputs.shape).float() # Fake
        if torch.cuda.is_available():
            labels_real = labels_real.cuda()
            labels_fake = labels_fake.cuda()
        loss_real = self.BCELoss(real_outputs, labels_real)
        loss_fake = self.BCELoss(fake_outputs, labels_fake)
        return (loss_real + loss_fake)/2

    def train_gan(self, generator, discriminator):
        torch.manual_seed(123)

        train_loader, val_loader, test_loader = get_data_loaders(self.bs)

        for epoch in range(self.start_epoch, self.epochs):
            total_batch = 0
            total_gen_loss = 0.0
            total_dis_loss = 0.0
            for data in train_loader:
                if torch.cuda.is_available():
                    data = data.cuda()
                data = data.permute(0,3,1,2)
                grey = data[:,0,:,:].view(-1,1,256,256)
                colour = data[:,1:3,:,:]
                # Train Discriminator
                self.dis_optimizer.zero_grad()
                dis_loss = self.train_discriminator(discriminator, generator, data)
                dis_loss.backward()
                self.dis_optimizer.step()
                # Train Generator
                self.gen_optimizer.zero_grad()
                gen_loss = self.train_generator(generator, discriminator, data)
                gen_loss.backward()
                self.gen_optimizer.step()

                total_batch += 1
                total_gen_loss += gen_loss.item()
                total_dis_loss += dis_loss.item()

            if self.save_model:
                gen_save_dict = {'model_state_dict': gen.state_dict(), 'optimizer_state_dict': self.gen_optimizer.state_dict()}
                dis_save_dict = {'model_state_dict': dis.state_dict(), 'optimizer_state_dict': self.dis_optimizer.state_dict()}
                torch.save(gen_save_dict, "/content/drive/MyDrive/APS360_Project/Models/Generator_" + get_model_name(gen.name, self.bs, self.lrg, epoch))
                torch.save(dis_save_dict, "/content/drive/MyDrive/APS360_Project/Models/Discriminator_" + get_model_name(dis.name, self.bs, self.lrd, epoch))

            self.show(data[:7])

            total_gen_loss = total_gen_loss/total_batch
            total_dis_loss = total_dis_loss/total_batch

            print("Epoch {}: Gen Loss: {} | Dis Loss: {}".format(epoch+1, total_gen_loss, total_dis_loss))

def init_weights(model, std=0.02):
    def init_func(m):
        classname = m.__class__.__name__
        if hasattr(m, 'weight') and 'Conv' in classname:
            nn.init.normal_(m.weight.data, mean=0.0, std=std)
            if hasattr(m, 'bias') and m.bias is not None:
                nn.init.constant_(m.bias.data, 0.0)
        elif hasattr(m, 'weight') and 'Linear' in classname:
            nn.init.normal_(m.weight.data, mean=0.0, std=std)
            if hasattr(m, 'bias') and m.bias is not None:
                nn.init.constant_(m.bias.data, 0.0)
        elif 'BatchNorm2d' in classname:
            nn.init.normal_(m.weight.data, 1., std)
            nn.init.constant_(m.bias.data, 0.)
    torch.manual_seed(123)
    model.apply(init_func)

from skimage.color import rgb2lab, lab2rgb
from torchvision import transforms
from PIL import Image

def to_lab(img):
    """
    img is a uint8 numpy array
    """
    img = rgb2lab(img)
    img[:,:,0] = img[:,:,0]/50-1
    img[:,:,1:3] = img[:,:,1:3]/110
    return img

def to_rgb(img):
    """
    img is a 1.0 float numpy array
    """
    img[:,:,0] = img[:,:,0]*50+50
    img[:,:,1:3] = img[:,:,1:3]*110
    img = lab2rgb(img)
    return img

def sk_greyscale(img):
    img = rgb2lab(img)
    img = img[:,:,0]/50-1
    return img

class DatasetLab(torch.utils.data.Dataset):
    def __init__(self, paths, transform=True):
        self.paths = paths
        self.transform = transform
        self.transformations = transforms.RandomChoice([
            transforms.RandomHorizontalFlip(1),
            transforms.RandomVerticalFlip(1),
            transforms.RandomErasing(1),
            transforms.RandomRotation(180),
            transforms.Lambda(lambda x:x)
        ])

    def augment(self, img):
        img = torch.from_numpy(img).permute(2,0,1)
        img = self.transformations(img)
        img = np.array(img.permute(1,2,0)).astype(np.uint8)
        return img

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, index):
        # Make sure that img is uint8 for converting to lab
        img = readImg(self.paths[index])
        if self.transform: img = self.augment(img)
        img = to_lab(img).astype(np.float32)
        return img


train_data = DatasetLab(train_paths)
val_data = DatasetLab(val_paths, False)
test_data = DatasetLab(test_paths, False)
samples = len(train_data) + len(val_data) + len(test_data)
print(samples)

img = train_data[0]
print(img.shape)
img = to_rgb(img)
plt.imshow(img)
plt.show()

# Max: {'L': 100.0, 'a': 98.2330538631131, 'b': 94.47812227647825}
# Min: {'L': 0.0, 'a': -86.18302974439501, 'b': -107.85730020669489}

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.2),
            nn.MaxPool2d(2,2)
        )
    def forward(self, x):
        x = self.model(x)
        return x

class ConvTBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvTBlock, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(in_channels*2, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Upsample(scale_factor=2)
        )
    def forward(self, x):
        x = self.model(x)
        return x

class UNetGeneratorLab(nn.Module):
    def __init__(self, in_channels=2, out_channels=2):
        super(UNetGeneratorLab, self).__init__()
        self.name = "UNetGeneratorLab"
        self.encoder = nn.Sequential(
            ConvBlock(in_channels, 8),
            ConvBlock(8, 16),
            ConvBlock(16, 32),
            ConvBlock(32, 64),
            ConvBlock(64, 128),
            ConvBlock(128, 256),
            ConvBlock(256, 512),
            ConvBlock(512, 1024),
        )

        self.decoder = nn.Sequential(
            ConvTBlock(1024, 512),
            ConvTBlock(512, 256),
            ConvTBlock(256, 128),
            ConvTBlock(128, 64),
            ConvTBlock(64, 32),
            ConvTBlock(32, 16),
            ConvTBlock(16, 8),
            ConvTBlock(8, out_channels)
        )
        self.output = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.Tanh()
        )


    def add_noise(self, grey):
        batches = len(grey)
        noise = torch.randn([batches, 1, 256, 256])
        if torch.cuda.is_available():
            noise = noise.cuda()
        x = torch.cat([grey, noise], 1)
        return x

    def forward(self, grey):
        x = self.add_noise(grey)
        encoder_outputs = []
        for block in self.encoder:
            x = block(x)
            encoder_outputs.append(x)

        for block in self.decoder:
            x = torch.cat([x, encoder_outputs.pop()], dim=1)
            x = block(x)

        return self.output(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.name = "Discriminator"
        self.conv = nn.Sequential(
            ConvBlock(3, 16),
            ConvBlock(16, 64),
            ConvBlock(64, 256),
            ConvBlock(256, 512),
        )
        self.output = nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.output(x)
        return x

"""# Lab UNet GAN Training

"""

gen = UNetGeneratorLab()
dis = Discriminator()

GanTrainer(gen, dis, epochs=100)

gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)
g.load_save(34)
g.start()

gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)
g.load_save(50)
g.start()

gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)
g.load_save(75)
g.start()

"""# Gen Evalutation

"""

gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)

losses = torch.zeros(100)

for epoch in range(94, 100):
    torch.manual_seed(123)
    train_loader, val_loader, test_loader = get_data_loaders(70)
    g.load_save(epoch)
    _, losses[epoch] = evaluate(gen, val_loader, nn.L1Loss())
    print("Epoch {}: Loss = {}".format(epoch, losses[epoch]))

l1_losses = [
0.10398387908935547,
0.11476525664329529,
0.10982495546340942,
0.11604945361614227,
0.12031019479036331,
0.11732041090726852,
0.1227002665400505,
0.12313000857830048,
0.12222187221050262,
0.12937164306640625,
0.11822660267353058,
0.129965141415596,
0.12014060467481613,
0.12627536058425903,
0.1298190802335739,
0.12248213589191437,
0.12389218062162399,
0.11756599694490433,
0.12499931454658508,
0.1410907357931137,
0.1270866096019745,
0.11828604340553284,
0.13998830318450928,
0.12394504249095917,
0.11400890350341797,
0.12515676021575928,
0.12428240478038788,
0.11888919770717621,
0.1253286749124527,
0.1370251178741455,
0.12581263482570648,
0.11970016360282898,
0.12306476384401321,
0.12431368976831436,
0.1219162717461586,
0.12105052173137665,
0.12230316549539566,
0.1267934888601303,
0.11956299841403961,
0.12284453958272934,
0.12393844127655029,
0.11857905983924866,
0.125991553068161,
0.12783847749233246,
0.12277675420045853,
0.12270992994308472,
0.12423385679721832,
0.127084881067276,
0.12663573026657104,
0.1256820112466812,
0.124106265604496,
0.1359107792377472,
0.1315813660621643,
0.12660638988018036,
0.1259162873029709,
0.13110648095607758,
0.12879061698913574,
0.12246675044298172,
0.1257033795118332,
0.12906913459300995,
0.12257499992847443,
0.14060306549072266,
0.1318451464176178,
0.13111823797225952,
0.12231902778148651,
0.12154868990182877,
0.12364134937524796,
0.12820342183113098,
0.12959441542625427,
0.13090509176254272,
0.1294691264629364,
0.14416539669036865,
0.12843847274780273,
0.1264122724533081,
0.1234811395406723,
0.12446717172861099,
0.13600267469882965,
0.13296619057655334,
0.12949731945991516,
0.13380973041057587,
0.14206309616565704,
0.11695701628923416,
0.11607096344232559,
0.12814076244831085,
0.1248466745018959,
0.14413878321647644,
0.13867022097110748,
0.12390752881765366,
0.12560555338859558,
0.1222153753042221,
0.12271726876497269,
0.14578376710414886,
0.11793666332960129,
0.11665191501379013,
0.12272711098194122,
0.11671244353055954,
0.1196574792265892,
0.1201263889670372,
0.13098670542240143,
0.1259831339120865,
]

def evaluate_gen(gen, dis, loader):
    total_loss = 0.0
    total_acc = 0.0
    total_epoch = 0
    with torch.no_grad():
        gen.eval()
        for i, data in enumerate(loader, 0):
            grey = data[:,:,:,0].reshape(-1,1,256,256)
            if torch.cuda.is_available(): grey = grey.cuda()
            images = torch.cat([grey, gen(grey)], dim=1)
            guesses = dis(images)
            labels = torch.ones(guesses.shape).float()
            if torch.cuda.is_available(): labels = labels.cuda()
            loss = nn.BCEWithLogitsLoss()(guesses, labels)
            total_loss += loss.item()
            total_acc += (guesses > 0).sum()/256
            total_epoch += len(data)
        gen.train()
    acc = total_acc / total_epoch
    loss = float(total_loss) / (i + 1)
    return acc, loss

import copy

gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)
g.load_save(99)

eval = copy.deepcopy(dis)
loss = torch.zeros(100)
acc = torch.zeros(100)

for epoch in range(100):
    torch.manual_seed(123)
    train_loader, val_loader, test_loader = get_data_loaders(70)
    g.load_save(epoch)
    acc[epoch], loss[epoch] = evaluate_gen(gen, eval, val_loader)
    print("Epoch {}: Loss = {}, Acc = {}".format(epoch, loss[epoch], acc[epoch]))

best_epochs = [91, 68]
gen = UNetGeneratorLab()
dis = Discriminator()

g = GanTrainer(gen, dis, epochs=100)

train_loader, val_loader, test_loader = get_data_loaders(70)
images = next(iter(val_loader)).permute(0,3,1,2)
if torch.cuda.is_available(): images = images.cuda()
for epoch in range(100):
    g.load_save(epoch)
    print("Epoch:", epoch)
    g.show(images)

"""# Transfer Learning"""

import torch
import torchvision.models as models

resnet_model = models.resnet50(pretrained=True)
# print(*list(resnet_model.children())[:-4], sep="\nStart\n")
# print(len(list(resnet_model.children())[:-4]))
resnet_model = torch.nn.Sequential(*list(resnet_model.children())[:-4])

img = readImg("/content/drive/MyDrive/APS360_Project/TestImage.jpg")/255
img = torch.from_numpy(img).float().permute(2,0,1).reshape(1,3,256,256)
img = mean_greyscale(img.permute(0,2,3,1).squeeze(0)).reshape(1,1,256,256)
img = torch.cat([img, img, img], dim=1)
resnet_model(img).shape

# import torch
# import torchvision.models as models
#
# resnet_model = models.resnet50(pretrained=True)
# resnet_model = torch.nn.Sequential(*list(resnet_model.children())[:-4])
# if torch.cuda.is_available():
#     resnet_model = resnet_model.cuda()
# for param in resnet_model.parameters():
#     param.requires_grad = False
class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, norm=True, dropout=False):
        super(ConvBlock, self).__init__()
        modules = []
        modules += [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)]
        if norm: modules += [nn.BatchNorm2d(out_channels)]
        if dropout: modules += [nn.Dropout(0.3)]
        modules += [nn.LeakyReLU(0.2)]
        modules += [nn.MaxPool2d(2,2)]
        self.model = nn.Sequential(*modules)
    def forward(self, x):
        x = self.model(x)
        return x

class ConvTBlock(nn.Module):
    def __init__(self, in_channels, out_channels, norm=True, dropout=False):
        super(ConvTBlock, self).__init__()
        modules = []
        modules += [nn.ConvTranspose2d(in_channels*2, out_channels, kernel_size=3, stride=1, padding=1)]
        if norm: modules += [nn.BatchNorm2d(out_channels)]
        if dropout: modules += [nn.Dropout(0.3)]
        modules += [nn.ReLU()]
        modules += [nn.Upsample(scale_factor=2)]
        self.model = nn.Sequential(*modules)
    def forward(self, x):
        x = self.model(x)
        return x

class UNetGeneratorLab2(nn.Module):
    def __init__(self, in_channels=2, out_channels=2):
        super(UNetGeneratorLab2, self).__init__()
        self.name = "UNetGeneratorLab2"
        self.encoder = nn.Sequential(
            ConvBlock(in_channels, 16),
            ConvBlock(16, 32),
            ConvBlock(32, 64),
            ConvBlock(64, 128),
            ConvBlock(128, 256),
            ConvBlock(256, 512),
            ConvBlock(512, 1024),
            ConvBlock(1024, 2048)
        )

        self.decoder = nn.Sequential(
            ConvTBlock(2048, 1024),
            ConvTBlock(1024, 512),
            ConvTBlock(512, 256),
            ConvTBlock(256, 128),
            ConvTBlock(128, 64),
            ConvTBlock(64, 32),
            ConvTBlock(32, 16),
            ConvTBlock(16, out_channels)
        )
        # self.resnet_block = nn.Sequential(
        #     ConvBlock(512, 512),
        #     ConvBlock(512, 512),
        #     ConvBlock(512, 1024)
        # )

        self.output = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.Tanh()
        )
    def add_noise(self, grey):
        batches = len(grey)
        noise = torch.randn([batches, 1, 256, 256])
        if torch.cuda.is_available():
            noise = noise.cuda()
        x = torch.cat([grey, noise], 1)
        return x

    def forward(self, grey):
        x = self.add_noise(grey)

        encoder_outputs = []
        for block in self.encoder:
            x = block(x)
            encoder_outputs.append(x)

        for block in self.decoder:
            x = torch.cat([x, encoder_outputs.pop()], dim=1)
            x = block(x)

        return self.output(x)

class Discriminator2(nn.Module):
    def __init__(self):
        super(Discriminator2, self).__init__()
        self.name = "Discriminator2"
        self.conv = nn.Sequential(
            ConvBlock(3, 16, dropout=False),
            ConvBlock(16, 64, dropout=False),
            ConvBlock(64, 256, dropout=False),
            ConvBlock(256, 512, dropout=False),
        )
        self.output = nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.output(x)
        return x

gen = UNetGeneratorLab2()
dis = Discriminator2()

g = GanTrainer(gen, dis, epochs=100, save_model=True)
g.start()
# val_loader = get_data_loader(val_data, 1)
# img = next(iter(val_loader))[:,:,:,:1].permute(0,3,1,2)
# print(img.shape)
# img = img.cuda()
# gen(img).shape

"""# Testing"""

model = UNetLab()
load_save_dict(model, optim.Adam(model.parameters(), lr=0.001), "/content/drive/MyDrive/APS360_Project/Models/"+get_model_name(model.name, 70, 0.001, 27))

train_loader, val_loader, test_loader = get_data_loaders(70)
test_acc, test_loss = evaluate(model, test_loader, nn.L1Loss())
print(test_acc, test_loss)

def test(model, name="/content/drive/MyDrive/APS360_Project/TestImage.jpg"):
    # name = "/content/drive/MyDrive/APS360_Project/OpenImages/train/data/fffcbc0b28c934f7.jpg"
    plt.imshow(readImg(name))
    plt.show()
    for func in greyscale_functions:
        grey = torch.from_numpy(func(readImg(name)).reshape(1,1,256,256)).float()
        if torch.cuda.is_available():
            grey = grey.cuda()
        out = model(grey).squeeze(0)
        print(out.shape)
        plt.imshow(out.detach().cpu().numpy())
        plt.show()

def test_lab_old(model, name="/content/drive/MyDrive/APS360_Project/TestImage.jpg"):
    img = readImg(name)/255
    plt.imshow(readImg(name))
    plt.show()
    model.eval()
    for func in greyscale_functions:
        grey = torch.from_numpy(func(img).reshape(1,1,256,256)).float()
        if torch.cuda.is_available():
            grey = grey.cuda()
        out = model(grey)
        out = out.detach()
        out = torch.cat([grey, out], dim=1).squeeze(0).permute(1,2,0).cpu().numpy()
        print(out.shape)
        out = to_rgb(out)
        plt.imshow(out)
        plt.show()
    model.train()

def test_lab(model, name="/content/drive/MyDrive/APS360_Project/TestImage.jpg"):
    img = readImg(name)
    plt.imshow(img)
    plt.show()
    model.eval()
    grey = torch.from_numpy(sk_greyscale(img).reshape(1,1,256,256)).float()
    if torch.cuda.is_available():
        grey = grey.cuda()
    out = model(grey)
    out = torch.cat([grey, out.detach()], dim=1).squeeze(0).permute(1,2,0).cpu().numpy()
    print(out.shape)
    out = to_rgb(out)
    plt.imshow(out)
    plt.show()
    model.train()


# test(model, train_paths[0])
# test_lab(gen)

def overfit(model):
    img = torch.from_numpy(train_data[0])
    grey = img[:,:,0].reshape(1,256,256)
    # colour =  img[:,:,1:3].permute(2,0,1)
    colour = model(grey.unsqueeze(0)).squeeze(0)
    img = torch.cat([grey, colour], dim=0)
    img = img.permute(1,2,0)
    img = to_rgb(img.detach().numpy())
    plt.imshow(img)
    plt.show()
# overfit()

gen = UNetGeneratorLab()
dis = Discriminator()
g = GanTrainer(gen, dis)

g.load_gen(99)

test_loader = get_data_loader(test_data, 70)
print(evaluate(gen, test_loader, nn.L1Loss()))

test_loader = get_data_loader(test_data, 70)
print(evaluate_gen(gen, dis, test_loader))

val_loader = get_data_loader(val_data, 70)
for data in val_loader:
    data = data.permute(0,3,1,2)
    if torch.cuda.is_available(): data = data.cuda()
    g.show(data)
    break

"""# Delete Files in Google Drive"""

# !pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

# from google.colab import auth
# from googleapiclient.discovery import build

# # Authenticate and create the Drive service client
# auth.authenticate_user()
# drive_service = build('drive', 'v3')

# response = drive_service.files().list(pageSize=1000).execute()
# files = response.get('files', [])

# while 'nextPageToken' in response:
#     page_token = response['nextPageToken']
#     response = drive_service.files().list(pageSize=1000, pageToken=page_token).execute()
#     files.extend(response.get('files', []))

# print(len(files))
# files.sort(key=lambda x: x['name'])
# for file in files:
#     if file['name'].endswith('png') and not file['name'].startswith('Q'):
#         print(file['name'])

# print(len(files))
# for file in files:
#     if file['name'].endswith('png') and not file['name'].startswith('Q'):
#         print(file['name'])
#         drive_service.files().delete(fileId=file['id']).execute()

"""# Model Demonstration"""

gen = UNetGeneratorLab()
dis = Discriminator()
g = GanTrainer(gen, dis)

g.load_gen(99)

demo_paths = get_paths("/content/drive/MyDrive/APS360_Project/TestImages/")
demo_data = DatasetLab(demo_paths, transform=False)
demo_loader = get_data_loader(demo_data, 7)
g.show(next(iter(demo_loader)).permute(0,3,1,2).cuda())

demo_paths = get_paths("/content/drive/MyDrive/APS360_Project/TestImages/")

for path in demo_paths:
    test_lab(gen, path)